## Week 02 Overview — Computing Environments & LLM Setup

From Your Laptop to Real Compute

This week, we move from basic setup to real computing environments.

Modern AI systems rarely run only on a personal laptop. In this course, you’ll learn how to work across:
	•	Local machines
	•	University research computing (CU RC)
	•	Cloud-style environments

This week is a setup-heavy week, and that’s intentional.

### Learning Objectives

By the end of Week 02, you should be able to:

	•	Explain the difference between local, research computing, and cloud environments
	•	Access CU Research Computing via the OnDemand portal
	•	Launch a Jupyter environment on RC
	•	Run a Large Language Model (LLM) locally or on RC using Ollama
	•	Understand why compute location matters for AI workflows

### Tools You’ll Use This Week

	•	CU Research Computing (RC)
	•	RC OnDemand Portal
	•	SSH keys
	•	Jupyter Notebooks
	•	Ollama (local or RC)
	•	GitHub (for lab instructions and scripts)

### What You’ll Do This Week

	1.	Activate or verify your CU Research Computing account
	2.	Access RC via the OnDemand portal
	3.	Launch a Jupyter session on RC
	4.	Run a basic Ollama model locally or on RC
	5.	Validate that your environment works end-to-end

This is about confidence, not speed.

###  Deliverables

	•	RC Access Verification (screenshot or short proof)
	•	Successful Ollama test run (local or RC)

⚠️ If you hit issues with RC access, contact rc-help@colorado.edu early.

### Estimated Time Commitment

	•	Setup & troubleshooting: ~3–4 hours
	•	Lab execution: ~1–2 hours

### Final Note

This week can feel frustrating — that’s normal.

The goal is not perfection.
The goal is that your environment works so future labs feel easier, not harder.

If something breaks, document it and ask for help. That’s a real-world AI skill.
